{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c81484c4",
   "metadata": {},
   "source": [
    "\n",
    "# Alu Breakpoint Analysis Workflow\n",
    "\n",
    "This notebook demonstrates how to load refined variants directly from their VCF/BAM sources, extract read-level breakpoint contexts, apply the Alu feature set (target site duplication and poly-A tail detection), and export the results to a TSV file for downstream analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85deb800",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from vesper.utils.common import load_variants\n",
    "from vesper.processors.reads import ReadProcessor\n",
    "from vesper.models.contexts import VariantContext\n",
    "from vesper.analysis.context_extractor import ContextExtractor\n",
    "from vesper.analysis.features import (\n",
    "    available_feature_sets,\n",
    "    get_feature_set,\n",
    "    ALU_FEATURE_SET,\n",
    ")\n",
    "from vesper.analysis.exporter import (\n",
    "    iter_feature_rows,\n",
    "    export_breakpoint_tsv,\n",
    "    default_columns,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac44a86",
   "metadata": {},
   "source": [
    "\n",
    "## Configuration\n",
    "\n",
    "Update the paths and parameters below to match your dataset. Each entry in `SAMPLES` should provide a refined VCF (typically `*.annotated.refined.vcf.gz`) and the corresponding BAM containing supporting reads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87d47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = [\n",
    "    {\n",
    "        \"sample_id\": \"sample1\",\n",
    "        \"vcf\": Path(\"/path/to/sample1.annotated.refined.vcf.gz\"),\n",
    "        \"bam\": Path(\"/path/to/sample1.sorted.merged.bam\"),\n",
    "    },\n",
    "]\n",
    "\n",
    "MOTIF_FILTER = \"SINE/Alu\"  # Use None to skip motif filtering\n",
    "MIN_CONFIDENCE = 0.8        # Set to None to skip confidence filtering\n",
    "MIN_SVLEN = 300             # Set to None to skip SV length filtering\n",
    "MAX_DIVERGENCE = 3          # Set to None to skip divergence filtering\n",
    "FEATURE_SET_NAME = \"alu\"   # See available_feature_sets() for options\n",
    "CONTEXT_SIZE = 30           # Number of bases to capture on each flank\n",
    "OUTPUT_TSV = Path(\"./output/alu_breakpoints.tsv\")\n",
    "DROP_COLUMNS = []  # Columns to omit from export\n",
    "STRICT_MODE = False         # If True, errors locating breakpoints will raise\n",
    "INCLUDE_SEQUENCE = True     # Capture read sequences in ExtractedSupportRead snapshots\n",
    "TEST_MODE = None           # Set to an integer to limit variants per sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115c9a2d",
   "metadata": {},
   "source": [
    "\n",
    "## Inspect available feature sets\n",
    "\n",
    "Use the cell below to review the registered feature sets and confirm the columns that will be produced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cee2a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_feature_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbfb958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_set = get_feature_set(FEATURE_SET_NAME)\n",
    "feature_set.columns()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bc4af7",
   "metadata": {},
   "source": [
    "\n",
    "## Load variant contexts\n",
    "\n",
    "This cell loads `VariantContext` objects directly from refined VCF/BAM pairs, applying any sample, motif, or confidence filters configured above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca9c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_variants = []\n",
    "variant_contexts = []\n",
    "\n",
    "for sample_cfg in SAMPLES:\n",
    "    sample_id = sample_cfg[\"sample_id\"]\n",
    "    vcf_path = sample_cfg[\"vcf\"]\n",
    "    bam_path = sample_cfg[\"bam\"]\n",
    "\n",
    "    variants = load_variants(vcf_path)\n",
    "\n",
    "    with ReadProcessor(bam_path) as read_proc:\n",
    "        for analysis in variants:\n",
    "            support_reads, nonsupport_reads = read_proc.get_read_groups(analysis.variant)\n",
    "            analysis.support_reads = support_reads\n",
    "            analysis.nonsupport_reads = nonsupport_reads\n",
    "            analysis._calculate_grouped_metrics()\n",
    "            analysis._calculate_confidence()\n",
    "\n",
    "            context = VariantContext.from_variant_analysis(\n",
    "                sample_id=sample_id,\n",
    "                analysis=analysis,\n",
    "                include_sequence=INCLUDE_SEQUENCE,\n",
    "            )\n",
    "\n",
    "            repeat_classes = [v.repeat_class for v in analysis.repeatmasker_results]\n",
    "            repeat_divergence = [v.divergence for v in analysis.repeatmasker_results]\n",
    "\n",
    "            if MIN_CONFIDENCE is not None and (context.confidence or 0.0) < MIN_CONFIDENCE:\n",
    "                continue\n",
    "            if MIN_SVLEN is not None and analysis.variant.sv_length < MIN_SVLEN:\n",
    "                continue\n",
    "            if MOTIF_FILTER is not None and MOTIF_FILTER != repeat_classes[0]: # if the top ranked result is not MOTIF_FILTER\n",
    "                continue\n",
    "            if MAX_DIVERGENCE is not None and repeat_divergence[0] > MAX_DIVERGENCE:\n",
    "                continue\n",
    "\n",
    "            selected_variants.append(analysis)\n",
    "            variant_contexts.append(context)\n",
    "\n",
    "print(f\"Loaded {len(variant_contexts)} variant contexts across {len(SAMPLES)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbab588",
   "metadata": {},
   "source": [
    "\n",
    "### Quick summary of loaded variants\n",
    "\n",
    "Optional: examine the distribution of variant counts per sample before extracting read contexts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8405a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_summary = None\n",
    "if variant_contexts:\n",
    "    summary = {}\n",
    "    for ctx in variant_contexts:\n",
    "        summary.setdefault(ctx.sample_id, 0)\n",
    "        summary[ctx.sample_id] += 1\n",
    "    ctx_summary = pd.DataFrame(\n",
    "        [(sample, count) for sample, count in summary.items()],\n",
    "        columns=[\"sample_id\", \"variants\"],\n",
    "    ).sort_values(\"variants\", ascending=False)\n",
    "else:\n",
    "    print(\"No contexts loaded. Adjust filters or cache path and rerun.\")\n",
    "\n",
    "ctx_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bb5801",
   "metadata": {},
   "source": [
    "\n",
    "## Extract read-level breakpoint contexts\n",
    "\n",
    "Instantiate a `ContextExtractor`, iterate through supporting reads, and apply the chosen feature set. The extractor returns one row per support read.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dff890",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extractor = ContextExtractor(context_size=CONTEXT_SIZE, strict=STRICT_MODE)\n",
    "rows = list(iter_feature_rows(variant_contexts, extractor, feature_set))\n",
    "print(f\"Generated {len(rows)} support-read contexts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a04d78",
   "metadata": {},
   "source": [
    "\n",
    "### Preview the annotated contexts\n",
    "\n",
    "Convert the rows to a DataFrame for quick inspection. By default, sequence columns can be noisy; the `DROP_COLUMNS` list controls whether they are written to disk in the export step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fe4e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview = None\n",
    "if rows:\n",
    "    preview = pd.DataFrame(rows, columns=default_columns(feature_set))\n",
    "else:\n",
    "    print(\"No rows generated.\")\n",
    "\n",
    "preview.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaaa666",
   "metadata": {},
   "source": [
    "\n",
    "## Export to TSV\n",
    "\n",
    "Write the full set of annotated support reads to disk. The returned DataFrame mirrors the file contents and can be used for additional exploration within the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b994746",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported = None\n",
    "if rows:\n",
    "    exported = export_breakpoint_tsv(\n",
    "        rows,\n",
    "        columns=default_columns(feature_set),\n",
    "        output_path=OUTPUT_TSV,\n",
    "        drop_columns=DROP_COLUMNS,\n",
    "    )\n",
    "    print(f\"Wrote {len(exported)} rows to {OUTPUT_TSV}\")\n",
    "else:\n",
    "    print(\"No rows to export.\")\n",
    "\n",
    "exported"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccb59e3",
   "metadata": {},
   "source": [
    "\n",
    "### Optional: basic QC metrics\n",
    "\n",
    "Use the exported DataFrame to perform quick quality checks, such as counting TSD detections or inspecting poly-A tail lengths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e1830",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if rows:\n",
    "    print(\"TSD detection counts:\")\n",
    "    print(exported[\"tsd_present\"].value_counts())\n",
    "    print(\"Poly-A detection counts:\")\n",
    "    print(exported[\"poly_a_present\"].value_counts())\n",
    "else:\n",
    "    print(\"Skipped QC metrics; no exported rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d9b03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vesper2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}